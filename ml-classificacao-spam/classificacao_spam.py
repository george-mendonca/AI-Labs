'''
‚úÖ Aprendizagem por Classifica√ß√£o ‚Äî Detec√ß√£o de Spam

üéØ Problema - Classificar mensagens como:
    0 = N√£o spam
    1 = Spam

üß† Modelo: Regress√£o Log√≠stica

üíª Implementa√ß√£o Python - Evolu√ß√µes Estruturais do Projeto:

    1. Cria√ß√£o da Classe GerarDataset
        - Implementa√ß√£o de uma classe respons√°vel por gerar dinamicamente um dataset sint√©tico de mensagens classificadas como spam (1) ou n√£o spam (0).
        - O m√©todo gerar_dataset foi definido como @staticmethod, permitindo gera√ß√£o direta do dataset sem necessidade de instanciar a classe.
        - Possibilidade de controlar: Tamanho do dataset e propor√ß√£o de spam (ex: 55%).
        - Inclus√£o de frases realistas, frases amb√≠guas e ru√≠do lingu√≠stico (erros de digita√ß√£o e varia√ß√µes).
        - Isso torna o problema menos trivial e mais pr√≥ximo de cen√°rios reais de NLP.

    2 Estrutura√ß√£o com Pipeline
        - Ado√ß√£o de Pipeline para encadear: Vetoriza√ß√£o com TF-IDF e classifica√ß√£o com Regress√£o Log√≠stica
        - Garante aplica√ß√£o consistente das etapas no treino e teste.
        - Evita vazamento de dados (data leakage), pois a vetoriza√ß√£o passa a ser ajustada apenas com dados de treino dentro de cada ciclo.
        - Melhora organiza√ß√£o do c√≥digo e aproxima a solu√ß√£o de padr√µes utilizados em produ√ß√£o.

    3 Melhoria na Vetoriza√ß√£o
        - Substitui√ß√£o do CountVectorizer por TfidfVectorizer.
        - Considera√ß√£o de unigrams e bigrams (ngram_range=(1,2)), capturando contexto adicional.
        - Melhor pondera√ß√£o da import√¢ncia das palavras.
        - Redu√ß√£o do impacto de termos muito frequentes.
        - Maior robustez frente a ru√≠do lingu√≠stico.

    4 Configura√ß√£o do Modelo
        - Uso de class_weight='balanced', preparando o modelo para poss√≠veis desequil√≠brios entre classes.
        - Defini√ß√£o de max_iter=1000, garantindo converg√™ncia adequada em datasets maiores.
        - Separa√ß√£o expl√≠cita entre vari√°veis independentes (X) e vari√°vel alvo (y).

    5 Estrat√©gia de Avalia√ß√£o
        - Divis√£o Treino/Teste
            - Uso de train_test_split com random_state para reprodutibilidade.
            - Possibilidade de uso de stratify=y para manter propor√ß√£o das classes.
        - Relat√≥rio de Classifica√ß√£o
            - Exibi√ß√£o de m√©tricas:
                - Precis√£o, Recall, F1-score e Acur√°cia
        - Permite an√°lise mais detalhada por classe (spam vs n√£o spam).

    6 Valida√ß√£o Cruzada (Cross-Validation)
        - Aplica√ß√£o de cross_val_score utilizando a Pipeline completa.
        - A vetoriza√ß√£o √© recalculada dentro de cada fold.
        - Evita vazamento de dados durante valida√ß√£o.
        - Fornece estimativa mais robusta da capacidade de generaliza√ß√£o do modelo.
        - A acur√°cia m√©dia obtida √© um indicador da estabilidade do modelo diante de varia√ß√µes no conjunto de treino/teste.

@author: George Mendon√ßa
@date: 2026-02-18
'''

# Importando bibliotecas
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.feature_extraction.text import TfidfVectorizer # Importando o vetorizador TF-IDF para converter texto em n√∫meros
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from gerar_dataset import GerarDataset

df = GerarDataset.gerar_dataset() # Gerando um dataset sint√©tico de mensagens de texto com classifica√ß√£o de spam usando a classe GerarDataset
X = df['mensagem']  # Agora passamos texto bruto (vari√°vel independente) para a Pipeline, que ir√° cuidar da vetoriza√ß√£o
y = df['spam'] # Vari√°vel alvo permanece a mesma

''' Cria√ß√£o da Pipeline
        A Pipeline ir√° encadear duas etapas:
            1. Vetoriza√ß√£o com TF-IDF
            2. Classifica√ß√£o com Regress√£o Log√≠stica '''
pipeline = Pipeline([
    (
        'vetorizador',
        TfidfVectorizer(
            stop_words=None, # N√£o removemos stop words para manter o contexto completo
            ngram_range=(1,2) # Consideramos unigrams e bigrams para capturar mais contexto nas mensagens
        )
    ),
    (
        'classificador',
        LogisticRegression(
            class_weight='balanced', # Ajusta pesos das classes para lidar com desbalanceamento
            max_iter=1000 # Garantindo converg√™ncia adequada do modelo em datasets maiores
        )
    )
])

''' Divis√£o dos dados em treino e teste '''
X_train, X_test, y_train, y_test = train_test_split(
    X, # Passamos o texto bruto para a Pipeline, que ir√° cuidar da vetoriza√ß√£o, evitando risco de vazamento de dado
    y, # Vari√°vel alvo permanece a mesma
    test_size=0.3, # 30% dos dados para teste, 70% para treino
    random_state=42, # Semente para reprodutibilidade
    stratify=y # Preserva a propor√ß√£o das classes em treino e teste
)

''' Treinando o modelo atrav√©s da Pipeline  '''
pipeline.fit(X_train, y_train)

''' Avalia√ß√£o do modelo no conjunto de teste '''
previsoes = pipeline.predict(X_test)

''' Exibindo relat√≥rio de classifica√ß√£o '''
relatorio = classification_report(y_test, previsoes)

print("Relat√≥rio de Classifica√ß√£o:")
print(relatorio)
print(" ")
print("    => Precis√£o - Propor√ß√£o de mensagens classificadas como spam que s√£o realmente spam (verdadeiros positivos / (verdadeiros positivos + falsos positivos))")
print("    => Recall - Propor√ß√£o de mensagens realmente spam que foram corretamente classificadas como spam (verdadeiros positivos / (verdadeiros positivos + falsos negativos))")
print("    => F1-score - M√©dia harm√¥nica entre precis√£o e recall, fornecendo uma √∫nica m√©trica para avaliar o desempenho do modelo")
print("    => Supporte - N√∫mero de amostras reais para cada classe (spam e n√£o spam) - Desbalanceamento pode ser observado aqui")
print("    => Macro avg - M√©dia das m√©tricas (precis√£o, recall, F1-score) calculada de forma simples, sem considerar o suporte de cada classe")
print("    => Weighted avg - M√©dia das m√©tricas (precis√£o, recall, F1-score) ponderada pelo suporte de cada classe, refletindo melhor o desempenho geral do modelo em casos de desbalanceamento")
print(" ")